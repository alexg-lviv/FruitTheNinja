{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:25.171791Z",
     "start_time": "2023-12-14T21:53:25.138029Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import time\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "CLASS_1 = 0\n",
    "CLASS_2 = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:25.178233Z",
     "start_time": "2023-12-14T21:53:25.174922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    0: \"fair\",\n",
    "    1: \"cheat-1_no-cooldown\",\n",
    "    2: \"cheat-2_no-dash\",\n",
    "    3: \"cheat-3_inf-slowmo\",\n",
    "    4: \"cheat-4_huge-damage\",\n",
    "    5: \"cheat-5_frozen-ninja\",\n",
    "}\n",
    "\n",
    "data_name_1 = config_dict[CLASS_1]\n",
    "data_name_2 = config_dict[CLASS_2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:25.183937Z",
     "start_time": "2023-12-14T21:53:25.181413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def preprocess_gt_csv(data_name):\n",
    "    filename = f\"train_data/gt/{data_name}.csv\"\n",
    "\n",
    "    columns_to_eval = [\n",
    "        \"global_mouse_position\",\n",
    "        \"button_cooldown_times\",\n",
    "        \"logical_frames_since_last_button_press\",\n",
    "        \"global_position\",\n",
    "        \"velocity\",\n",
    "        \"fruits_cut_this_frame_list\",\n",
    "        \"fruits_hit_ninjas_ass_this_frame_list\",\n",
    "        \"fruits_on_screen_this_frame_list\",\n",
    "        \"fruits_spawned_this_frame_list\",\n",
    "        \"stupid_fucking_fruits_that_died_this_frame_list\",\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(filename, converters={column: literal_eval for column in columns_to_eval})\n",
    "\n",
    "    df[\"fruits_spawned_num\"] = df[\"fruits_spawned_this_frame_list\"].str.len()\n",
    "    df[\"fruits_on_screen_num\"] = df[\"fruits_on_screen_this_frame_list\"].str.len()\n",
    "    df[\"fruits_hit_num\"] = df[\"fruits_hit_ninjas_ass_this_frame_list\"].str.len()\n",
    "    df[\"fruits_missed_num\"] = df[\"stupid_fucking_fruits_that_died_this_frame_list\"].str.len()\n",
    "\n",
    "    projectiles = [\"Apple\", \"Banana\", \"Grape\", \"Pineapple\", \"Watermelon\", \"Coconut\", \"Cherry\"]\n",
    "\n",
    "    df[\"fruit_name_spawned\"] = df[\"fruits_spawned_this_frame_list\"].apply(lambda x: projectiles.index(x[0][\"name\"]) if len(x) != 0 else -1)\n",
    "\n",
    "    for butt in [\"b1\", \"b2\", \"b3\", \"b4\"]:\n",
    "        df[butt] = df[\"button_cooldown_times\"].apply(lambda j: j[butt])\n",
    "\n",
    "    general_needed = [\n",
    "        \"cheat_flag\",\n",
    "        \"frame_count\",\n",
    "        \"session_id\",\n",
    "        \"score\",\n",
    "        \"combo\",\n",
    "        \"is_combo_going\",\n",
    "        \"time_left_seconds\",\n",
    "        \"can_dash\",\n",
    "    ]\n",
    "    buttons_needed = [\n",
    "        \"b1\", \"b2\", \"b3\", \"b4\",\n",
    "    ]\n",
    "\n",
    "    df = df[general_needed + buttons_needed]\n",
    "    df[general_needed] = df[general_needed].astype(int)\n",
    "\n",
    "    if data_name == \"cheat-4_huge-damage\":  # its too fucking huge\n",
    "        df[\"score\"] *= 0.0001\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:25.194814Z",
     "start_time": "2023-12-14T21:53:25.192449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def preprocess_synthetic_csv(data_name):\n",
    "    filename = f\"train_data/synthetic/{data_name}_50-games.csv\"\n",
    "    df = pd.read_csv(filename).drop([\"Unnamed: 0\"], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:25.208817Z",
     "start_time": "2023-12-14T21:53:25.197643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   cheat_flag  frame_count  session_id  score  combo  is_combo_going  \\\n0           0            1  8455078507      0      0               0   \n1           0            2  8455078507      0      0               0   \n2           0            3  8455078507      0      0               0   \n3           0            4  8455078507      0      0               0   \n4           0            5  8455078507      0      0               0   \n\n   time_left_seconds  can_dash        b1        b2        b3        b4  \n0          43.868229         1  2.999291  0.083167  2.992171  0.126076  \n1          43.851845         1  2.999809  0.097893  2.993055  0.121729  \n2          43.835456         1  2.999999  0.113775  2.993886  0.117455  \n3          43.819062         1  2.999863  0.130800  2.994664  0.113254  \n4          43.802663         1  2.999399  0.148953  2.995390  0.109127  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cheat_flag</th>\n      <th>frame_count</th>\n      <th>session_id</th>\n      <th>score</th>\n      <th>combo</th>\n      <th>is_combo_going</th>\n      <th>time_left_seconds</th>\n      <th>can_dash</th>\n      <th>b1</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>8455078507</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.868229</td>\n      <td>1</td>\n      <td>2.999291</td>\n      <td>0.083167</td>\n      <td>2.992171</td>\n      <td>0.126076</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>8455078507</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.851845</td>\n      <td>1</td>\n      <td>2.999809</td>\n      <td>0.097893</td>\n      <td>2.993055</td>\n      <td>0.121729</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3</td>\n      <td>8455078507</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.835456</td>\n      <td>1</td>\n      <td>2.999999</td>\n      <td>0.113775</td>\n      <td>2.993886</td>\n      <td>0.117455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>4</td>\n      <td>8455078507</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.819062</td>\n      <td>1</td>\n      <td>2.999863</td>\n      <td>0.130800</td>\n      <td>2.994664</td>\n      <td>0.113254</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>5</td>\n      <td>8455078507</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.802663</td>\n      <td>1</td>\n      <td>2.999399</td>\n      <td>0.148953</td>\n      <td>2.995390</td>\n      <td>0.109127</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_synthetic_data = preprocess_synthetic_csv(data_name_1)\n",
    "fair_gt_data = preprocess_gt_csv(data_name_1)\n",
    "\n",
    "fair_synthetic_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:30.301711Z",
     "start_time": "2023-12-14T21:53:25.222033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   cheat_flag  frame_count  session_id  score  combo  is_combo_going  \\\n0           1            1  3066053919      0      0               0   \n1           1            2  3066053919      0      0               0   \n2           1            3  3066053919      0      0               0   \n3           1            4  3066053919      0      0               0   \n4           1            5  3066053919      0      0               0   \n\n   time_left_seconds  can_dash  b1  b2  b3  b4  \n0          41.244696         1   0   0   0   0  \n1          41.226906         1   0   0   0   0  \n2          41.209092         1   0   0   0   0  \n3          41.191254         1   0   0   0   0  \n4          41.173391         1   0   0   0   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cheat_flag</th>\n      <th>frame_count</th>\n      <th>session_id</th>\n      <th>score</th>\n      <th>combo</th>\n      <th>is_combo_going</th>\n      <th>time_left_seconds</th>\n      <th>can_dash</th>\n      <th>b1</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3066053919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.244696</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3066053919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.226906</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>3066053919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.209092</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3066053919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.191254</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3066053919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.173391</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheat_synthetic_data = preprocess_synthetic_csv(data_name_2)\n",
    "cheat_gt_data = preprocess_gt_csv(data_name_2)\n",
    "\n",
    "cheat_synthetic_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:33.125245Z",
     "start_time": "2023-12-14T21:53:30.299259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "((491248, 10), (491248,))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic = pd.concat([df.copy().drop([\"cheat_flag\", \"session_id\"], axis=1) for df in [fair_synthetic_data, cheat_synthetic_data]])\n",
    "y_synthetic = pd.concat([df[\"cheat_flag\"] for df in [fair_synthetic_data, cheat_synthetic_data]])\n",
    "\n",
    "X_synthetic.shape, y_synthetic.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:33.220599Z",
     "start_time": "2023-12-14T21:53:33.125579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "((62104, 10), (62104,))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gt = pd.concat([df.copy().drop([\"cheat_flag\", \"session_id\"], axis=1) for df in [fair_gt_data, cheat_gt_data]])\n",
    "y_gt = pd.concat([df[\"cheat_flag\"] for df in [fair_gt_data, cheat_gt_data]])\n",
    "\n",
    "X_gt.shape, y_gt.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:33.221103Z",
     "start_time": "2023-12-14T21:53:33.193234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "((294748, 10), (196500, 10), (294748,), (196500,))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_synthetic, y_synthetic, test_size=0.4, random_state=42, shuffle=True\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:33.331038Z",
     "start_time": "2023-12-14T21:53:33.219094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier( random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    MLPClassifier(max_iter=1000, random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:33.331227Z",
     "start_time": "2023-12-14T21:53:33.285260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors model:\n",
      "Train time: 0.2 sec,  Train score: 0.999,  Val score: 0.998,  Gt score: [ 0.545 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Decision Tree model:\n",
      "Train time: 0.2 sec,  Train score: 1.000,  Val score: 1.000,  Gt score: [ 0.991 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Random Forest model:\n",
      "Train time: 7.0 sec,  Train score: 1.000,  Val score: 1.000,  Gt score: [ 0.997 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Neural Net model:\n",
      "Train time: 17.6 sec,  Train score: 1.000,  Val score: 1.000,  Gt score: [ 0.661 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Naive Bayes model:\n",
      "Train time: 0.0 sec,  Train score: 1.000,  Val score: 1.000,  Gt score: [ 0.991 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "QDA model:\n",
      "Train time: 0.1 sec,  Train score: 0.386,  Val score: 0.385,  Gt score: [ 0.363 ]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    print(f\"{name} model:\")\n",
    "\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    val_score = clf.score(X_test, y_test)\n",
    "    gt_score = clf.score(X_gt, y_gt)\n",
    "\n",
    "    print(f\"Train time: {(end - start):.1f} sec,  Train score: {train_score:.3f},  Val score: {val_score:.3f},  Gt score: [ {gt_score:.3f} ]\")\n",
    "    print(\"-\" * 150)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:05:23.982910Z",
     "start_time": "2023-12-14T21:04:44.527726Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.lstm(x)\n",
    "#         out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout = 0.25\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "\n",
    "        out = self.fc(h_out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:41.993364Z",
     "start_time": "2023-12-14T21:53:41.988538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 50\n",
    "output_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "batch_size = 60"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:41.994248Z",
     "start_time": "2023-12-14T21:53:41.991850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_subset = TensorDataset(\n",
    "    torch.FloatTensor(X_synthetic.to_numpy()).unsqueeze(1),\n",
    "    torch.LongTensor(y_synthetic.to_numpy()),\n",
    ")\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_subset = TensorDataset(\n",
    "    torch.FloatTensor(X_gt[: len(X_gt) // 4].to_numpy()).unsqueeze(1),\n",
    "    torch.LongTensor(y_gt[: len(y_gt) // 4].to_numpy()),\n",
    ")\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "gt_dataset = TensorDataset(\n",
    "    torch.FloatTensor(X_gt[len(X_gt) // 4 :].to_numpy()).unsqueeze(1),\n",
    "    torch.LongTensor(y_gt[len(y_gt) // 4 :].to_numpy()),\n",
    ")\n",
    "gt_loader = DataLoader(gt_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:42.065526Z",
     "start_time": "2023-12-14T21:53:41.997566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alorthius/anaconda3/envs/big_data/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=0, threshold=1, factor=0.5, threshold_mode=\"abs\", min_lr=0.0005, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:42.406585Z",
     "start_time": "2023-12-14T21:53:42.067264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train    1/5 ] loss: 0.1587, accuracy: [ 94.6003% ]\n",
      "[ Validation 1/5 ] loss: 0.0937, accuracy: [ 98.5830% ]\n",
      "[ Gt         1/5 ], accuracy: [ 81.3238% ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_corrects = 0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = train_corrects / len(train_subset) * 100\n",
    "    print(f\"\\n[ Train    {epoch + 1}/{num_epochs} ] loss: {train_loss:.4f}, accuracy: [ {train_acc:<7.4f}% ]\")\n",
    "\n",
    "\n",
    "    val_loss = 0\n",
    "    val_corrects = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = val_corrects / len(val_subset) * 100\n",
    "    print(f\"[ Validation {epoch + 1}/{num_epochs} ] loss: {val_loss:.4f}, accuracy: [ {val_acc:<7.4f}% ]\")\n",
    "\n",
    "\n",
    "    gt_corrects = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in gt_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            gt_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    gt_acc = gt_corrects / len(gt_dataset) * 100\n",
    "    print(f\"[ Gt         {epoch + 1}/{num_epochs} ], accuracy: [ {gt_acc:<7.4f}% ]\")\n",
    "\n",
    "    scheduler.step(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:53:53.638925Z",
     "start_time": "2023-12-14T21:53:42.407150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.1833, dtype=torch.float64), 0.0)"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), f\"weights/lstm_{CLASS_1}-{CLASS_2}.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:57:02.012189Z",
     "start_time": "2023-12-14T21:57:02.006581Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
